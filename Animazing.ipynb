{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Animazing",
      "provenance": [],
      "collapsed_sections": [
        "kTh1OI3KgePv",
        "iuyWQEvf0e-h",
        "wE8Hxyuuz-Jr",
        "KxiWLiab0pTk",
        "XZVnzBOS0uKf",
        "4tgvuf-d01MC"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTh1OI3KgePv"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3zFWqlTgoep"
      },
      "source": [
        "#prevent random disconnects\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "!pip install anvil-uplink"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "EbBa3j0tya3q"
      },
      "source": [
        "#@title Install or update DeepFaceLab from Github { vertical-output: true }\n",
        "#Mode = \"install\" #@param [\"install\", \"update\"]\n",
        "\n",
        "\n",
        "pretrain_link = \"https://github.com/chervonij/DFL-Colab/releases/download/\"\n",
        "pretrain_link = pretrain_link+\"pretrain-CelebA/pretrain_CelebA.zip\"\n",
        "\n",
        "m = \"install\"\n",
        "\n",
        "from pathlib import Path\n",
        "if (m == \"install\"):\n",
        "  !git clone https://github.com/iperov/DeepFaceLab.git\n",
        "\n",
        "  # fix linux warning\n",
        "  # /usr/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n",
        "  fin = open(\"/usr/lib/python3.6/multiprocessing/semaphore_tracker.py\", \"rt\")\n",
        "  data = fin.read()\n",
        "  data = data.replace('if cache:', 'if False:')\n",
        "  fin.close()\n",
        "\n",
        "  fin = open(\"/usr/lib/python3.6/multiprocessing/semaphore_tracker.py\", \"wt\")\n",
        "  fin.write(data)\n",
        "  fin.close()\n",
        "else:\n",
        "  %cd /content/DeepFaceLab\n",
        "  !git pull\n",
        "\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install -r /content/DeepFaceLab/requirements-colab.txt\n",
        "!pip install --upgrade scikit-image\n",
        "!apt-get install cuda-10-0\n",
        "\n",
        "if not Path(\"/content/pretrain\").exists():\n",
        "  print(\"Downloading Pretrain faceset ... \")\n",
        "  !wget -q --no-check-certificate -r $pretrain_link -O /content/pretrain_faceset.zip\n",
        "  !mkdir /content/pretrain\n",
        "  !unzip -q /content/pretrain_faceset.zip -d /content/pretrain/\n",
        "  !rm /content/pretrain_faceset.zip\n",
        "\n",
        "if not Path(\"/content/pretrain_Q96\").exists():\n",
        "  print(\"Downloading Q96 pretrained model ...\")\n",
        "  !wget -q --no-check-certificate -r 'https://github.com/chervonij/DFL-Colab/releases/download/Q96_model_pretrained/Q96_model_pretrained.zip' -O /content/pretrain_Q96.zip\n",
        "  !mkdir /content/pretrain_Q96\n",
        "  !unzip -q /content/pretrain_Q96.zip -d /content/pretrain_Q96/\n",
        "  !rm /content/pretrain_Q96.zip\n",
        "\n",
        "if not Path(\"/content/workspace\").exists():\n",
        "  !mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model  \n",
        "\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"\\nDone!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0eITIhof5Zh"
      },
      "source": [
        "#download updated code files from gDrive\n",
        "\n",
        "import shutil\n",
        "!gdown --id 16eKsWHCH35NzHi_lqr95wtlxyudwL_v7\n",
        "!gdown --id 1PImbxTmD7C2kywqY8HG5j9mO4RNVjZUU\n",
        "\n",
        "shutil.move(\"/content/ModelBase.py\", \"/content/DeepFaceLab/models/ModelBase.py\")\n",
        "shutil.move(\"/content/Model.py\", \"/content/DeepFaceLab/models/Model_SAEHD/Model.py\")\n",
        "\n",
        "!gdown --id 1JYXyQreln8n3eQjT9Fld2vLBzIdg9qJW\n",
        "!gdown --id 1bavD-FFdtOkXfiU2n03kEtYTLlAuarPz\n",
        "\n",
        "shutil.move(\"/content/Merger.py\", \"/content/DeepFaceLab/mainscripts/Merger.py\")\n",
        "shutil.move(\"/content/MergerConfig.py\", \"/content/DeepFaceLab/merger/MergerConfig.py\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuyWQEvf0e-h"
      },
      "source": [
        "# Face Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI0TfZOfBvc7"
      },
      "source": [
        "#make directory of known faces\n",
        "!mkdir known\n",
        "!wget https://www.princeton.edu/sites/default/files/styles/scale_1440/public/images/2021/04/Trevor-Noah_CAA-Speakers_Photo-Credit-Gavin-Bond.jpg?itok=ilEPaXVg -O known/trevor.jpg\n",
        "!wget https://www.biography.com/.image/t_share/MTczNjEwODI2NTg5MDg3MTI0/michelle-obama-gettyimages-85246899.jpg -O known/michelle.jpg\n",
        "!wget https://www.thenews.com.pk/assets/uploads/updates/2021-04-17/821680_7280106_natalie-portman_updates.jpg -O known/natalie.jpg\n",
        "!wget https://www.biography.com/.image/t_share/MTE4MDAzNDEwNzg2ODEzNDU0/jimmy-fallon-11818465-1-402.jpg -O known/jimmy.jpg\n",
        "!wget https://media.gettyimages.com/photos/indian-bollywood-actress-kareena-kapoor-khan-looks-on-during-the-of-picture-id814885222?s=612x612 -O known/karina.jpg\n",
        "!wget https://www.24newshd.tv/digital_images/large/2020-05-08/hania-amir-teases-fahad-mustafa-with-her-new-tik-tok-video-1588934215-4295.jpg -O known/hania.jpg\n",
        "!wget https://www.samaa.tv/wp-content/uploads/2019/11/hamza-ali-abbasi-1.jpg -O known/hamza.jpg\n",
        "!wget https://pbs.twimg.com/profile_images/1271836263268655106/6sWADZ0m.jpg -O known/ahad.jpg\n",
        "!wget https://pbs.twimg.com/media/C0V7W29WIAASlIF.jpg -O known/ali.jpg\n",
        "\n",
        "\n",
        "#install face recognition library\n",
        "!pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yST4GiUt0hOb"
      },
      "source": [
        "import face_recognition   ##Detecting and recogniting faces\n",
        "import cv2     ## intracting with images\n",
        "import os       ## For Reading the file name\n",
        "import shutil\n",
        "from google.colab.patches import cv2_imshow ## we are importing cv2_imshow from google.colab.patches because google colab doesn't support cv2.imshow() funciton.\n",
        "\n",
        "#function that can be used to read and reshape the images\n",
        "def read_img(path):\n",
        "   img = cv2.imread(path) ## reading image\n",
        "   (h,w) = img.shape[:2]  ## fetching height and width\n",
        "   width = 500            ## hard coding width\n",
        "   ratio = width / float(w) ## preparing a ration for height\n",
        "   height = int(h * ratio)  ## generating new height\n",
        "   return cv2.resize(img,(width,height)) ##return the reshaped image\n",
        "\n",
        "!mkdir face2\n",
        "\n",
        "#The Face_recognition library recognizes faces by generating different-different encodings\n",
        "#for each known face and unknown face and then both the encodings get compared and \n",
        "#whichever encoding is matched it shows the label name as output.\n",
        "#Preparing encodings for Known Faces\n",
        "known_encodings = [] \n",
        "known_names = []\n",
        "known_dir = 'known' ##Known directory path\n",
        "for file in os.listdir(known_dir):\n",
        "  print(known_dir + '/' + file)\n",
        "  img = read_img(known_dir + '/' + file) ##Reading all the images\n",
        "  img_enc = face_recognition.face_encodings(img)[0] ##face encodings\n",
        "  known_encodings.append(img_enc) \n",
        "  known_names.append(file.split('.')[0])\n",
        "print(known_names) ## Printing all the known labels\n",
        "\n",
        "#prepare encodings for unknown faces, \n",
        "#comparing them with known encoding and recognizing the faces\n",
        "unknown_dir = 'unknown' ##UNknown Images Directory\n",
        "\n",
        "imgList = os.listdir('/content/workspace/data_dst/aligned')\n",
        "imgList.sort()\n",
        "\n",
        "for file in imgList:\n",
        " print(\"Processing\",file)\n",
        "\n",
        " if file != None:\n",
        "  img = read_img('/content/workspace/data_dst/aligned' + '/' + file)##reading images\n",
        "  #print(img)\n",
        "\n",
        "  #if img[0] != None:\n",
        "  img_enc = face_recognition.face_encodings(img)[0]##Encodings\n",
        "  #print(img_enc)\n",
        "  \n",
        "  results = face_recognition.compare_faces(known_encodings,img_enc)\n",
        " \n",
        " res = [i for i, val in enumerate(results) if val]\n",
        "\n",
        " if len(res) > 0:\n",
        "  print(res)\n",
        "  name = known_names[res[0]]\n",
        "  path = '/content/workspace/data_dst/aligned' + '/' + file\n",
        "  if name != \"hania\":\n",
        "    shutil.move(path, \"/content/face2\")\n",
        "    print(file, \"moved\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybfeC_20rBbG"
      },
      "source": [
        "# Anvil Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqBe-bIOrISp"
      },
      "source": [
        "import anvil.server\n",
        "#pass your key as the function parameter\n",
        "anvil.server.connect(\"RTGURUU3BMIXOYBUC7SJK5PV-UZNAAWUAFEUHU7GT\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE8Hxyuuz-Jr"
      },
      "source": [
        "# Anvil Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWtW_dRykoXr"
      },
      "source": [
        "#before you get input from user, you should have workspace already in here\n",
        "import shutil\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "#link for ws1: https://drive.google.com/file/d/1e0jF-jr-U-M0d38dfUU5XQMygBhIYVht/view?usp=sharing\n",
        "\n",
        "@anvil.server.callable\n",
        "def getDstVid(vidID, face):\n",
        "  print(\"inside get DST\")\n",
        "  zipped = None\n",
        "\n",
        "  if vidID == 1:\n",
        "    !gdown --id 1e0jF-jr-U-M0d38dfUU5XQMygBhIYVht             #download ws1\n",
        "    zipped = 'v1.zip'\n",
        "  if vidID == 2 and face == 1:\n",
        "    print(\"ws2f1 to be downloaded\")\n",
        "    !gdown --id 1Dcz2kW7P7JCnUfcdvMfScgtFKyIlP-jj\n",
        "    zipped = 'v2f1.zip'\n",
        "  if vidID == 2 and face == 2:\n",
        "    !gdown --id                                               #download ws2\n",
        "    zipped = 'v2f2.zip'\n",
        "\n",
        "  with ZipFile(zipped, 'r') as zipObj:\n",
        "    zipObj.extractall()\n",
        "  \n",
        "  #download model/base/merger\n",
        "  #!gdown id --\n",
        "  \n",
        "  return 1  \n",
        "\n",
        "#getDstVid(2, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtfaxmTyhA_k"
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw13XRMWj84x"
      },
      "source": [
        "#gdown only works for direct links\n",
        "#if we get the link from frontend we need to save it in a variable\n",
        "#gdown consideres the variables as the link instead of the data of the variable\n",
        "\n",
        "import re\n",
        "@anvil.server.callable\n",
        "def getSrcLink(link):\n",
        "\n",
        "  print(\"inside get SRC\")\n",
        "  pattern = \"d/(.*?)/view\"\n",
        "  file_id = re.search(pattern, link).group(1)\n",
        "\n",
        "  #video can be downloaded but for images we need zipped folder\n",
        "  destination = '/content/workspace/data_src.mp4'\n",
        "  download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "  return \"Input Received\"\n",
        "\n",
        "#getSrcLink(\"https://drive.google.com/file/d/1MMnSxwBYzl5q8a91qQ5yWtP5vi3Hqg8P/view?usp=sharing\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aofBqICaCC5L"
      },
      "source": [
        "#sending mail through google\n",
        "\n",
        "import anvil.google.mail\n",
        "import anvil.google.auth\n",
        "\n",
        "@anvil.server.callable\n",
        "def send_mail(email_from,to,subject,body):\n",
        "  email_addr = anvil.google.auth.get_user_email()\n",
        "  print (\"%s is now logged in\" % email_addr)\n",
        "  anvil.google.mail.send(from_address = email_from , to=\"Anvil Admin<l174557@lhr.nu.edu.pk>\", subject=\"Request for New Destionation Vid\", text = body)\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxiWLiab0pTk"
      },
      "source": [
        "# Import/Export from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "z4w_sUzgOQmL"
      },
      "source": [
        "#@title Import from Drive\n",
        "\n",
        "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"models\"]\n",
        "Archive_name = \"kate.zip\" #@param {type:\"string\"}\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  unzip_cmd=\" -q \"+Archive_name\n",
        "  \n",
        "  %cd $path\n",
        "  copy_cmd = \"/content/drive/My\\ Drive/\"+Archive_name+\" \"+path\n",
        "  !cp $copy_cmd\n",
        "  !unzip $unzip_cmd    \n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "  \n",
        "print(\"Done!\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y3WfuwoNXqC",
        "outputId": "f050593b-bac0-4a5f-fefa-578aae353be1"
      },
      "source": [
        "#@title Export to Drive { form-width: \"30%\" }\n",
        "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"merged\", \"merged_mask\", \"models\", \"result video\", \"result_mask video\"]\n",
        "Archive_name = \"kate.zip\" #@param {type:\"string\"}\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  zip_cmd=\"-r -q \"+Archive_name+\" \"\n",
        "  \n",
        "  %cd $path\n",
        "  zip_cmd+=mode\n",
        "  !zip $zip_cmd\n",
        "  copy_cmd = \" \"+Archive_name+\"  /content/drive/My\\ Drive/\"\n",
        "  !cp $copy_cmd\n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"merged\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged\")\n",
        "elif Mode == \"merged_mask\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged_mask\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "elif Mode == \"result video\":\n",
        "  !cp /content/workspace/result.mp4 /content/drive/My\\ Drive/\n",
        "elif Mode == \"result_mask video\":\n",
        "  !cp /content/workspace/result_mask.mp4 /content/drive/My\\ Drive/\n",
        "  \n",
        "print(\"Done!\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZVnzBOS0uKf"
      },
      "source": [
        "# Preprocess Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "H4w55xne1t-O"
      },
      "source": [
        "@anvil.server.callable\n",
        "def preprocess():\n",
        "  #@title Extract frames\n",
        "  print(\"extracting frames\")\n",
        "  Video = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "  %cd \"/content\"\n",
        "  cmd = \"DeepFaceLab/main.py videoed extract-video \"\n",
        "  cmd+= \" --input-file workspace/data_src.* --output-dir workspace/data_src/ --output-ext jpg --fps 25\"\n",
        "    \n",
        "  !python $cmd\n",
        "\n",
        "  #@title Detect faces\n",
        "  print(\"detecting faces\")\n",
        "  Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "  Detector = \"S3FD\" #@param [\"S3FD\", \"S3FD (whole face)\"]\n",
        "  Debug = False #@param {type:\"boolean\"}\n",
        "\n",
        "  detect_type = \"s3fd\"\n",
        "  dbg = \" --output-debug\" if Debug else \" --no-output-debug\"\n",
        "\n",
        "  folder = \"workspace/\"+Data\n",
        "  folder_aligned = folder+\"/aligned\"\n",
        "\n",
        "  cmd = \"DeepFaceLab/main.py extract --input-dir \"+folder+\" --output-dir \"+folder_aligned\n",
        "  cmd+=\" --detector \"+detect_type+\" --force-gpu-idxs 0\"+ dbg\n",
        "  cmd+=\" --face-type whole_face --image-size 512 --jpeg-quality 90 --max-faces-from-image 0\"\n",
        "\n",
        "  %cd \"/content\"\n",
        "  !python $cmd\n",
        "\n",
        "  preprocess()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQWD_NoSaJLi",
        "outputId": "e1986000-fd03-4d4c-d6cc-bb2979ab7d78"
      },
      "source": [
        "#@anvil.server.callable\n",
        "\n",
        "def preprocess():\n",
        "  #@title Extract frames\n",
        "  print(\"extracting frames\")\n",
        "  Video = \"data_dst\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "  %cd \"/content\"\n",
        "  cmd = \"DeepFaceLab/main.py videoed extract-video \"\n",
        "  cmd+= \" --input-file workspace/data_dst.* --output-dir workspace/data_dst/ --output-ext jpg --fps 30\"\n",
        "    \n",
        "  !python $cmd\n",
        "\n",
        "  #@title Detect faces\n",
        "  print(\"detecting faces\")\n",
        "  Data = \"data_dst\" #@param [\"data_src\", \"data_dst\"]\n",
        "  Detector = \"S3FD\" #@param [\"S3FD\", \"S3FD (whole face)\"]\n",
        "  Debug = False #@param {type:\"boolean\"}\n",
        "\n",
        "  detect_type = \"s3fd\"\n",
        "  dbg = \" --output-debug\" if Debug else \" --no-output-debug\"\n",
        "\n",
        "  folder = \"workspace/\"+Data\n",
        "  folder_aligned = folder+\"/aligned\"\n",
        "\n",
        "  cmd = \"DeepFaceLab/main.py extract --input-dir \"+folder+\" --output-dir \"+folder_aligned\n",
        "  cmd+=\" --detector \"+detect_type+\" --force-gpu-idxs 0\"+ dbg\n",
        "  cmd+=\" --face-type whole_face --image-size 512 --jpeg-quality 90 --max-faces-from-image 0\"\n",
        "\n",
        "  %cd \"/content\"\n",
        "  !python $cmd\n",
        "\n",
        "preprocess()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "extracting frames\n",
            "/content\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/workspace/data_dst.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: mp41\n",
            "    creation_time   : 2021-05-29T21:24:27.000000Z\n",
            "    encoder         : Bandicam 4.5.8.1673 / GDI / Intel Quick Sync Video\n",
            "    encoder-eng     : Bandicam 4.5.8.1673 / GDI / Intel Quick Sync Video\n",
            "  Duration: 00:00:16.60, start: 0.000000, bitrate: 2218 kb/s\n",
            "    Stream #0:0(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 848x400 [SAR 1:1 DAR 53:25], 2017 kb/s, 25.84 fps, 30 tbr, 30k tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-05-29T21:24:27.000000Z\n",
            "      handler_name    : VideoHandler\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 193 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-05-29T21:24:27.000000Z\n",
            "      handler_name    : SoundHandler\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[0;33mIncompatible pixel format 'rgb24' for codec 'mjpeg', auto-selecting format 'yuvj444p'\n",
            "\u001b[0m\u001b[1;34m[swscaler @ 0x5627d2644000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
            "\u001b[0mOutput #0, image2, to '/content/workspace/data_dst/%5d.jpg':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(eng): Video: mjpeg, yuvj444p(pc), 848x400 [SAR 1:1 DAR 53:25], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-05-29T21:24:27.000000Z\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc57.107.100 mjpeg\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
            "frame=  498 fps=155 q=2.0 Lsize=N/A time=00:00:16.60 bitrate=N/A dup=69 drop=0 speed=5.18x    \n",
            "video:31811kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "Done.\n",
            "detecting faces\n",
            "/content\n",
            "Extracting faces...\n",
            "Running on Tesla K80\n",
            "100% 498/498 [17:57<00:00,  2.16s/it]\n",
            "-------------------------\n",
            "Images found:        498\n",
            "Faces detected:      1989\n",
            "-------------------------\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dkGA9TcNa6zw",
        "outputId": "0fcde38c-c8a8-4d6c-edb7-d27e36b608d1"
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"FILESRC\", 'zip', '/content/workspace/data_dst')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/FILESRC.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tgvuf-d01MC"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "Z0Kya-PJLDhv"
      },
      "source": [
        "@anvil.server.background_task\n",
        "def trainer():\n",
        "  print(\"inside trainer\")\n",
        "  cmd = \"DeepFaceLab/main.py train\"\n",
        "  cmd+= \" --training-data-src-dir workspace/data_src/aligned --training-data-dst-dir workspace/data_dst/aligned --pretraining-data-dir pretrain \"\n",
        "  cmd+= \"--model-dir workspace/model --model SAEHD --force-gpu-idxs 0\" \n",
        "\n",
        "  Silent_Start = False #@param {type:\"boolean\"}\n",
        "\n",
        "  savedmodel = False\n",
        "  if savedmodel == True:\n",
        "    if Silent_Start:\n",
        "      cmd+= \" --silent-start\"\n",
        "\n",
        "  print(\"training started\")\n",
        "\n",
        "  train_cmd = (cmd)\n",
        "  !python $train_cmd\n",
        "\n",
        "  \n",
        "\n",
        "@anvil.server.callable\n",
        "def trainModel():\n",
        "  \"\"\"Launch a single background task.\"\"\"\n",
        "  task = anvil.server.launch_background_task('trainer')\n",
        "  return task\n",
        "  \n",
        "@anvil.server.callable\n",
        "def killTrainer(task):\n",
        "  print(\"killing task\")\n",
        "  task.kill()\n",
        "  return 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUZsdmFGcLwK"
      },
      "source": [
        "import cv2\n",
        "import base64\n",
        "  \n",
        "\n",
        "\n",
        "@anvil.server.callable\n",
        "def preview():\n",
        "\n",
        "  file = '/content/workspace/model/New_SAEHD_preview_SAEHD.jpg'\n",
        "  image = open(file, 'rb')\n",
        "  image_read = image.read()\n",
        "  image_64_encode = base64.encodebytes(image_read)\n",
        "\n",
        "  image_binary = base64.b64decode(image_64_encode)\n",
        "  my_media = anvil.BlobMedia(content_type=\"img/jpg\", content=image_binary, name=\"acme.png\")\n",
        "  return my_media\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAvduZIw08Bo"
      },
      "source": [
        "# Merge Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "A3Y8K22Sv9Gn"
      },
      "source": [
        "import base64\n",
        "\n",
        "@anvil.server.callable\n",
        "def merge():\n",
        "  #@title Merge\n",
        "  Model = \"SAEHD\" #@param [\"SAEHD\", \"Quick96\" ]\n",
        "\n",
        "  cmd = \"DeepFaceLab/main.py merge --input-dir workspace/data_dst --output-dir workspace/data_dst/merged --output-mask-dir workspace/data_dst/merged_mask --aligned-dir workspace/data_dst/aligned --force-gpu-idxs 0 --model-dir workspace/model --model \"+Model\n",
        "\n",
        "  %cd \"/content\"\n",
        "  !python $cmd\n",
        "\n",
        "  #@title Get result video \n",
        "  Mode = \"result video\" #@param [\"result video\", \"result_mask video\"]\n",
        "  Copy_to_Drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "  if Mode == \"result video\":\n",
        "    !python DeepFaceLab/main.py videoed video-from-sequence --input-dir workspace/data_dst/merged --output-file workspace/result.mp4 --reference-file workspace/data_dst.mp4 --bitrate 16 --include-audio \n",
        "    if Copy_to_Drive:\n",
        "      !cp /content/workspace/result.mp4\n",
        "\n",
        "  with open(\"/content/workspace/result.mp4\", \"rb\") as videoFile:\n",
        "    text = base64.b64encode(videoFile.read())\n",
        "    vid = (base64.b64decode(text))\n",
        "\n",
        "    my_media = anvil.BlobMedia(content_type=\"vid/mp4\", content=vid, name=\"vid.mp4\")\n",
        "    return my_media"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r-YfPv91Fpc"
      },
      "source": [
        "# Anvil Wait Forever"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFRJJ2Ef1Qga"
      },
      "source": [
        "anvil.server.wait_forever()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}